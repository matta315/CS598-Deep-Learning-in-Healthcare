{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1\n",
    "\n",
    "## Overview\n",
    "\n",
    "Preparing the data, computing basic statistics and constructing simple models are essential steps for data science practice. In this homework, you will use clinical data as raw input to perform **Heart Failure Prediction**. For this homework, **Python** programming will be required. See the attached skeleton code as a start-point for the programming questions.\n",
    "\n",
    "This homework assumes familiarity with Pandas. If you need a Pandas crash course, we recommend working through [100 Pandas Puzzles](https://github.com/ajcr/100-pandas-puzzles), the solutions are also available at that link. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "DATA_PATH = \"../HW1-lib/data/\"\n",
    "TRAIN_DATA_PATH = DATA_PATH + \"train/\"\n",
    "VAL_DATA_PATH = DATA_PATH + \"val/\"\n",
    "    \n",
    "sys.path.append(\"../HW1-lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Raw Data\n",
    "\n",
    "For this homework, we will be using a clinical dataset synthesized from [MIMIC-III](https://www.nature.com/articles/sdata201635).\n",
    "\n",
    "Navigate to `TRAIN_DATA_PATH`. There are three CSV files which will be the input data in this homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $TRAIN_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**events.csv**\n",
    "\n",
    "The data provided in *events.csv* are event sequences. Each line of this file consists of a tuple with the format *(pid, event_id, vid, value)*. \n",
    "\n",
    "For example, \n",
    "\n",
    "```\n",
    "33,DIAG_244,0,1\n",
    "33,DIAG_414,0,1\n",
    "33,DIAG_427,0,1\n",
    "33,LAB_50971,0,1\n",
    "33,LAB_50931,0,1\n",
    "33,LAB_50812,1,1\n",
    "33,DIAG_425,1,1\n",
    "33,DIAG_427,1,1\n",
    "33,DRUG_0,1,1\n",
    "33,DRUG_3,1,1\n",
    "```\n",
    "\n",
    "- **pid**: De-identified patient identier. For example, the patient in the example above has pid 33. \n",
    "- **event_id**: Clinical event identifier. For example, DIAG_244 means the patient was diagnosed of disease with ICD9 code [244](http://www.icd9data.com/2013/Volume1/240-279/240-246/244/244.htm); LAB_50971 means that the laboratory test with code 50971 was conducted on the patient; and DRUG_0 means that a drug with code 0 was prescribed to the patient. Corresponding lab (drug) names can be found in `{DATA_PATH}/lab_list.txt` (`{DATA_PATH}/drug_list.txt`).\n",
    "- **vid**: Visit identifier. For example, the patient has two visits in total. Note that vid is ordinal. That is, visits with bigger vid occour after that with smaller vid.\n",
    "- **value**: Contains the value associated to an event (always 1 in the synthesized dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hf_events.csv**\n",
    "\n",
    "The data provided in *hf_events.csv* contains pid of patients who have been diagnosed with heart failure (i.e., DIAG_398, DIAG_402, DIAG_404, DIAG_428) in at least one visit. They are in the form of a tuple with the format *(pid, vid, label)*. For example,\n",
    "\n",
    "```\n",
    "156,0,1\n",
    "181,1,1\n",
    "```\n",
    "\n",
    "The vid indicates the index of the first visit with heart failure of that patient and a label of 1 indicates the presence of heart failure. **Note that only patients with heart failure are included in this file. Patients who are not mentioned in this file have never been diagnosed with heart failure.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**event_feature_map.csv**\n",
    "\n",
    "The *event_feature_map.csv* is a map from an event_id to an integer index. This file contains *(idx, event_id)* pairs for all event ids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Descriptive Statistics [20 points]\n",
    "\n",
    "Before starting analytic modeling, it is a good practice to get descriptive statistics of the input raw data. In this question, you need to write code that computes various metrics on the data described previously. A skeleton code is provided to you as a starting point.\n",
    "\n",
    "The definition of terms used in the result table are described below:\n",
    "\n",
    "- **Event count**: Number of events recorded for a given patient.\n",
    "- **Encounter count**: Number of visits recorded for a given patient.\n",
    "\n",
    "Note that every line in the input file is an event, while each visit consists of multiple events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the following code cell to implement the required statistics.**\n",
    "\n",
    "Please be aware that **you are NOT allowed to change the filename and any existing function declarations.** Only `numpy`, `scipy`, `scikit-learn`, `pandas` and other built-in modules of python will be available for you to use. The use of `pandas` library is suggested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# PLEASE USE THE GIVEN FUNCTION NAME, DO NOT CHANGE IT.\n",
    "\n",
    "def read_csv(filepath=TRAIN_DATA_PATH):\n",
    "\n",
    "    '''\n",
    "    Read the events.csv and hf_events.csv files. \n",
    "    Variables returned from this function are passed as input to the metric functions.\n",
    "    \n",
    "    NOTE: remember to use `filepath` whose default value is `TRAIN_DATA_PATH`.\n",
    "    '''\n",
    "    \n",
    "    events = pd.read_csv(filepath + 'events.csv')\n",
    "    hf = pd.read_csv(filepath + 'hf_events.csv')\n",
    "\n",
    "    return events, hf\n",
    "\n",
    "def event_count_metrics(events, hf):\n",
    "\n",
    "    '''\n",
    "    TODO : Implement this function to return the event count metrics.\n",
    "    \n",
    "    Event count is defined as the number of events recorded for a given patient.\n",
    "    '''\n",
    "    ## your code here\n",
    "    \n",
    "    # Count events per patient\n",
    "    event_counts = events['pid'].value_counts().reset_index()\n",
    "    event_counts.columns = ['pid', 'event_count']\n",
    "    \n",
    "    # Merge event counts with HF status\n",
    "    patient_df = event_counts.merge(hf, on='pid', how='left')\n",
    "    normal_patients = patient_df[patient_df['label'].isna()]\n",
    "    hf_patients = patient_df[patient_df['label']==1]\n",
    "    \n",
    "    # Calculate metrics for HF patients\n",
    "    avg_hf_event_count = hf_patients['event_count'].mean() if not hf_patients.empty else None\n",
    "    max_hf_event_count = hf_patients['event_count'].max() if not hf_patients.empty else None\n",
    "    min_hf_event_count = hf_patients['event_count'].min() if not hf_patients.empty else None\n",
    "    \n",
    "    # Calculate metrics for normal patients\n",
    "    avg_norm_event_count = normal_patients['event_count'].mean() if not normal_patients.empty else None\n",
    "    max_norm_event_count = normal_patients['event_count'].max() if not normal_patients.empty else None\n",
    "    min_norm_event_count = normal_patients['event_count'].min() if not normal_patients.empty else None\n",
    "\n",
    "    return avg_hf_event_count, max_hf_event_count, min_hf_event_count, \\\n",
    "           avg_norm_event_count, max_norm_event_count, min_norm_event_count\n",
    "\n",
    "def encounter_count_metrics(events, hf):\n",
    "\n",
    "    '''\n",
    "    TODO : Implement this function to return the encounter count metrics.\n",
    "    \n",
    "    Encounter count is defined as the number of visits recorded for a given patient. \n",
    "    '''\n",
    "    # your code here\n",
    "    \n",
    "    vid_counts = events.groupby('pid')['vid'].nunique().reset_index()\n",
    "    vid_counts.columns = ['pid', 'encounter_count']\n",
    "\n",
    "    patient_df = vid_counts.merge(hf, on='pid', how='left')\n",
    "    normal_patients = patient_df[patient_df['label'].isna()]\n",
    "    hf_patients = patient_df[patient_df['label']==1]\n",
    "    \n",
    "    avg_hf_encounter_count = hf_patients['encounter_count'].mean() if not hf_patients.empty else None\n",
    "    max_hf_encounter_count = hf_patients['encounter_count'].max() if not hf_patients.empty else None\n",
    "    min_hf_encounter_count = hf_patients['encounter_count'].min() if not hf_patients.empty else None\n",
    "    avg_norm_encounter_count = normal_patients['encounter_count'].mean() if not normal_patients.empty else None\n",
    "    max_norm_encounter_count = normal_patients['encounter_count'].max() if not normal_patients.empty else None\n",
    "    min_norm_encounter_count = normal_patients['encounter_count'].min() if not normal_patients.empty else None\n",
    "    \n",
    "    return avg_hf_encounter_count, max_hf_encounter_count, min_hf_encounter_count, \\\n",
    "           avg_norm_encounter_count, max_norm_encounter_count, min_norm_encounter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, hf = read_csv(TRAIN_DATA_PATH)\n",
    "\n",
    "#Compute the event count metrics\n",
    "start_time = time.time()\n",
    "event_count = event_count_metrics(events, hf)\n",
    "end_time = time.time()\n",
    "print((\"Time to compute event count metrics: \" + str(end_time - start_time) + \"s\"))\n",
    "print(event_count)\n",
    "\n",
    "#Compute the encounter count metrics\n",
    "start_time = time.time()\n",
    "encounter_count = encounter_count_metrics(events, hf)\n",
    "end_time = time.time()\n",
    "print((\"Time to compute encounter count metrics: \" + str(end_time - start_time) + \"s\"))\n",
    "print(encounter_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
